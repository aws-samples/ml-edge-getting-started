{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification @Edge with SageMaker Neo + Pytorch + Resnet18\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you'll:\n",
    "   - Get a pre-trained model from the torchvision model zoo: Resnet18\n",
    "   - Prepare the model to compile it with Neo\n",
    "   - Compile the model for the target: **X86_64**\n",
    "   - Get the optimized model and run a simple local test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "In this step, we are installing some python modules for operating with the pre-trained model Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update -y && apt install -y libgl1\n",
    "!pip install torch==1.7.0 torchvision==0.8.0 opencv-python dlr==1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load a pre-trained model from the model zoo and trace it with Pytorch JIT\n",
    "\n",
    "In this step, we are preparing the model for being compiled by using Amazon SageMaker Neo.\n",
    "\n",
    "Amazon SageMaker Neo requires the model is formatted correctly, with the `name` and the `shape` of the expected data inputs for the trained model.\n",
    "\n",
    "The format provided can be `json` or `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "img_size = 224\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "input_shape = [1, 3, img_size, img_size]\n",
    "trace = torch.jit.trace(resnet18.float().eval(), torch.zeros(input_shape).float())\n",
    "trace.save(\"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a package with the model and upload to S3\n",
    "\n",
    "Amazon SageMaker Neo is expecting the model, compressed in a `tar.gz` format, stored in an Amazon S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "model_name='resnet18'\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(\"model.pth\")\n",
    "    f.list()\n",
    "\n",
    "s3_uri = sagemaker_session.upload_data('model.tar.gz', key_prefix=f'{model_name}/model')\n",
    "print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compile the model with SageMaker Neo (X86_64)\n",
    "\n",
    "Amazon SageMaker Neo is used for optimizing a ML model on the basis of the provided Target Platform information.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "`InputConfig`: Information in `json` format related to the ML model, such as location onf the model in the Amazon S3 Bucket, Input Shape for the ML model, and Framework used. Full list of compatible Frameworks is available in the official [AWS documentation page](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-frameworks.html).\n",
    "\n",
    "`OutputConfig`: Information in `json` format related to the Target Platform for which the model should be optimized, with OS and base Arch, and storage location on Amazon S3 Bucket where the compiled model will be stored. Full list of supported devices, architecture, and systems is available in the official [AWS documentation page](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-devices.html).\n",
    "\n",
    "For this example, we are targeting as platform the instance where this notebook is executed. The information related to the instance are: `OS` -> LINUX, `Arch` -> X86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "compilation_job_name = f'{model_name}-pytorch-{int(time.time()*1000)}'\n",
    "\n",
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_uri,\n",
    "        'DataInputConfig': f'{{\"input\": [1,3,{img_size},{img_size}]}}',\n",
    "        'Framework': 'PYTORCH'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/',\n",
    "        'TargetPlatform': { \n",
    "            'Os': 'LINUX', \n",
    "            'Arch': 'X86_64',\n",
    "        },\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 900 }\n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Download the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_path = f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/model-LINUX_X86_64.tar.gz'\n",
    "!aws s3 cp $output_model_path /tmp/model.tar.gz\n",
    "!rm -rf model_classifier && mkdir model_classifier\n",
    "!tar -xzvf /tmp/model.tar.gz -C model_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Run the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the labels and a sample image\n",
    "\n",
    "For testing our compiled model, we are downloading an input image to provide for the prediction, and the list of labels used for training the original Resnet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "labels_url='https://raw.githubusercontent.com/DenWhiteHouse/DogClassification/master/imagenet1000_clsidx_to_labels.txt'\n",
    "image_url='https://sagemaker-examples.readthedocs.io/en/latest/_images/cat2.jpg'\n",
    "\n",
    "if not os.path.exists('cat.jpg'):\n",
    "    urllib.request.urlretrieve(labels_url, 'labels.txt')\n",
    "    urllib.request.urlretrieve(image_url, 'cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty parser for the labels\n",
    "labels = {}\n",
    "\n",
    "for l in open('labels.txt', 'r').read().splitlines():\n",
    "    l = l.strip().replace('{', '').replace('}', '')\n",
    "    l = l[:-1] if l.endswith(',') else l\n",
    "    cls_id,label = [t.strip() for t in l.split(':')]\n",
    "    labels[int(cls_id)] = label[1:-1] # remove the single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "# Print first 10 labels\n",
    "print(json.dumps(dict(itertools.islice(labels.items(), 10)), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model using the runtime DLR\n",
    "\n",
    "Compiled model with Amazon SageMaker Neo can be managed and executed by using the DLR module.\n",
    "\n",
    "DLR is a compact, common runtime for deep learning models and decision tree models compiled by AWS SageMaker Neo, TVM, or Treelite.\n",
    "\n",
    "For more information, please visit the official [GitHub repository for DLR](https://github.com/neo-ai/neo-ai-dlr).\n",
    "\n",
    "For loading the model using the DLR library, we have to provide the following information:\n",
    "\n",
    "1. Location of the compiled model\n",
    "2. Processor type of the target platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlr\n",
    "# load the model (CPU x86_64)\n",
    "model = dlr.DLRModel('model_classifier', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and make it squared if needed\n",
    "img = cv2.cvtColor(cv2.imread('cat.jpg'), cv2.COLOR_BGR2RGB)\n",
    "h, w, c = img.shape\n",
    "\n",
    "if w != h: # pad the image and make it square\n",
    "    sqr_size = max(h,w)\n",
    "    sqr_img = np.zeros((sqr_size, sqr_size, c), dtype=np.uint8)\n",
    "    sqr_img[:h, :w],img = img,sqr_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize the image on the basis of the input shape defined for the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to the expected size+transform it to pytorch/imagenet format\n",
    "x = cv2.resize(img, (img_size, img_size)).astype(np.float32) / 255.0\n",
    "# normalize\n",
    "x -= [0.485, 0.456, 0.406]\n",
    "x /= [0.229, 0.224, 0.225]\n",
    "x = x.transpose(2,0,1) # HWC --> CHW\n",
    "c, h, w = x.shape\n",
    "x = x.reshape(1,c,h,w) # CHW --> NCHW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Execute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.run(x)\n",
    "idx = np.argmax(y)\n",
    "print(f\"Class id: {idx}, Score: {y[0][0][idx]}, Label: {labels[idx]}\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! :)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
